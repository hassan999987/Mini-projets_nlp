{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projet_Nlp_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrlaWpJ7Bf4y"
      },
      "source": [
        "L’analyse de sentiments est l’une des applications qu’on rencontre couramment en NLP. En effet, pour beaucoup de business, il est important de connaître l’avis des clients/utilisateurs. Un outil qui permet de déterminer si un produit ou service est plutôt bien vu ou plutôt mal vu, de façon automatique en se basant sur du texte écrit en langage naturel, est forcément une bonne idée. Dans cet article, je vous propose d’implémenter un système d’analyse de sentiments en utilisant notre model puis utilisation le modèle “cousin” de BERT CamemBERT.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yg5jQS484ZH"
      },
      "source": [
        "### Creation model LTSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIZ7BAb_879h"
      },
      "source": [
        "import torch\n",
        "import seaborn\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9pPQ05fC8zk",
        "outputId": "e0087fb9-ba6f-4a40-e855-831c169877ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7czuBjZ9ZzY",
        "outputId": "ef4505f9-8b9f-4c08-eb07-dc353f27c601"
      },
      "source": [
        "!unzip  /content/drive/MyDrive/ML/NLP/archive.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/ML/NLP/archive.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n",
            "  inflating: valid.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-c38CUZ985w"
      },
      "source": [
        "Le jeu de données est constitué de reviews de films ressemblant à ça :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pLImwQOy9Pbg",
        "outputId": "32ce750d-376a-4b6b-f048-0f8ccfc65d4d"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/train.csv\")\n",
        "dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>film-url</th>\n",
              "      <th>review</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-135259/c...</td>\n",
              "      <td>Si vous cherchez du cinéma abrutissant à tous ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-172430/c...</td>\n",
              "      <td>Trash, re-trash et re-re-trash...! Une horreur...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-15105/cr...</td>\n",
              "      <td>Et si, dans les 5 premières minutes du film, l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-188629/c...</td>\n",
              "      <td>Mon dieu ! Quelle métaphore filée ! Je suis ab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-23514/cr...</td>\n",
              "      <td>Premier film de la saga Kozure Okami, \"Le Sabr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... polarity\n",
              "0           0  ...        0\n",
              "1           1  ...        0\n",
              "2           2  ...        0\n",
              "3           3  ...        0\n",
              "4           4  ...        1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY7g14T89Y3Z"
      },
      "source": [
        "reviews = dataset['review'].values.tolist()\n",
        "sentiments = dataset['polarity'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUKstk-x-CTY"
      },
      "source": [
        "Pour pouvoir passer nos données au modèle, il va falloir qu’elles soient encodées. Encoder, c’est donner une représentation numérique (en vrai vectorielle) au texte exactement comme le fait un embedding classique. La bibliothèque keras , tokenize() fournit un analyseur lexical  L'analyseur de ce module renvoie également des jetons en donne les commantaires a ce analyseur et par la methode texts_to_sequences() en Transforme chaque commantaire a une séquence d'entiers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH3wVDwY-T1Z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "max_fatures = 512\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "X = tokenizer.texts_to_sequences(reviews)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "sentiments = torch.tensor(sentiments)\n",
        "\n",
        "sentiments\n",
        "y = pd.get_dummies(sentiments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DajnUIoGABIg",
        "outputId": "a3a881af-52db-4bf5-aced-f39030839a54"
      },
      "source": [
        "print(reviews[0])\n",
        "print(X[0])\n",
        "print(y[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si vous cherchez du cinéma abrutissant à tous les étages,n'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l'on se dirige vers la banlieue,on y trouve tout plein d'intégristes musulmans prêts à faire sauter le caisson d'une ambassadrice américaine.Nauséeux.Alors on se dit qu'on va au moins pouvoir apprécier la déconnade d'un classique buddy-movie avec le jeune agent aux dents longues obligé de faire équipe avec un vieux lou complètement timbré.Mais d'un côté,on a un Jonathan Rhys-meyers fayot au possible,et de l'autre un John Travolta en total délire narcissico-badass,crâne rasé et bouc proéminent à l'appui.Sinon,il n'y a aucun scénario.Seulement,des poursuites débiles sur l'autoroute,Travolta qui étale 10 mecs à l'arme blanche en 8 mouvements(!!)ou laisse son associé se faire démolir la tronche pendant qu'il scrute à la jumelle.Ca pourrait être un plaisir coupable,tellement c'est \"hénaurme\",c'est juste de la daube dans la droite lignée d'un \"Transporteur\",\"Taken\"ou \"Banlieue 13\".\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  44  67\n",
            "  16  76   6  79   8 248 438  16  11   2   9  39  19  67 253   8  45 133\n",
            "   1 193  57   4  58   9  80  12  81  41  12  20  44 136  29 420   4  22\n",
            "  58 225  32 304   6  57   3  59 114  22  29 240 135 120  27  97   4  53\n",
            " 290  26   3 163  68   1  57  26   5 305  20  53 197  22  21   5  27 431\n",
            "   2   1 502   5 370  11   2   6 471  24 203  21 172  52 384  13  36  10\n",
            "   6  11  47 234  35  29  57   4 281  69   6   4 421 462  64   5 238 192\n",
            "  30  30 134   1   4  18   4  53  47]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAApapXHAYIB"
      },
      "source": [
        "l'etape suivant est divisé le jeu de données en deux sous-ensembles : pour les données d'entraînement et pour les données de test. Avec train_test_split() , vous n'avez pas besoin de diviser l'ensemble de données manuellement. Par défaut, la fonction train_test_split de Sklearn effectue des partitions aléatoires pour les deux sous-ensembles.\n",
        "\n",
        "70% pour train et 30% pour test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X0ysTMvAMNY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_test_size = 0.30\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=split_test_size, random_state=42) \n",
        "                            # test_size = 0.3 is 30%, 42 is the answer to everything"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9H0a02yAs_J"
      },
      "source": [
        "LSTM :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr-XnhOQBJC5"
      },
      "source": [
        "En passe a la derniere etape qui consiste a cration le model d'analyse sentiment on uilise le model LSTM pour notre projet , LTSM est un réseau Long short-term memory (LSTM), en français réseau récurrent à mémoire court et long terme ou plus explicitement réseau de neurones récurrents à mémoire court-terme et long terme,\n",
        "\n",
        "premièrement en instance le model on a deux sortie soit postive ou negative et adam comme optimazers :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNCWddPRACqf",
        "outputId": "c00ea930-803f-4863-ce04-db03842b6b28"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(optimizer = 'adam',loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 297, 128)          65536     \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 297, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 320,730\n",
            "Trainable params: 320,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMygu8NFCVUS"
      },
      "source": [
        "puis en entraine le model par donnant le nombre d'epechqe 20 qui le nombre de fois pour entraine et batch size eqal 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9API4n1AxmD",
        "outputId": "8486776c-efcf-4263-b704-14a3cc8e1908"
      },
      "source": [
        "model.fit(X_train,y_train, epochs = 5, batch_size=1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "112/112 [==============================] - 159s 1s/step - loss: 0.5222 - accuracy: 0.7470\n",
            "Epoch 2/5\n",
            "112/112 [==============================] - 154s 1s/step - loss: 0.3535 - accuracy: 0.8467\n",
            "Epoch 3/5\n",
            "112/112 [==============================] - 154s 1s/step - loss: 0.3346 - accuracy: 0.8535\n",
            "Epoch 4/5\n",
            "112/112 [==============================] - 153s 1s/step - loss: 0.3292 - accuracy: 0.8569\n",
            "Epoch 5/5\n",
            "112/112 [==============================] - 153s 1s/step - loss: 0.3128 - accuracy: 0.8642\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f279267cd90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdpoboh0CnSS"
      },
      "source": [
        "En a la precision final equal 0.8642 En comparant cette resultas avec les tranformers en trouve que CamemBERT a une precision eqal = 94.10 dont plus grand donc on focalusé dans la deuxieme section a utiliser les tranfomres pre entriné pour creer un application web qui est cabale de detecter si un commantaire est positive ou negative "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmtbg_BW8zI0"
      },
      "source": [
        "### Utiliser un tranformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnOV3Se99r8z"
      },
      "source": [
        "CamemBERT est une “version” de RoBERTa pré-entraînée sur un jeu de données francophone. RoBERTa lui-même est une version de BERT pour laquelle, certains hyperparamètres du pré-entraînement ont été modifiés et l’objectif de prédiction de phrase suivante (Next-Sentence Prediction) a été supprimé. CamemBERT hérite donc des avantages de BERT.\n",
        "\n",
        "Pour l’implémentation de notre modèle d’analyse de sentiments, nous utiliserons la bibliothèque Transformers de HuggingFace ansi que PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PalN8fncHP3H",
        "outputId": "c60b2016-0a84-4431-a2fe-b71a2334aee3"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install flask==0.12.2  \n",
        "!pip install transformers>=4.0\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: flask==0.12.2 in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->flask==0.12.2) (2.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x19gqVOpHR93"
      },
      "source": [
        "on uziper le fhicher projet.rar qui contient lesp pages web et ses codes .css "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLtDa6XjmjQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a568f3eb-9e1a-4962-fe92-b1a24fde0a5f"
      },
      "source": [
        "!unrar x projet.rar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from projet.rar\n",
            "\n",
            "Creating    static                                                    OK\n",
            "Creating    static/assets                                             OK\n",
            "Creating    static/assets/css                                         OK\n",
            "Extracting  static/assets/css/fontawesome.css                            \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/css/owl.css                                    \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/css/templatemo-finance-business.css            \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Creating    static/assets/fonts                                       OK\n",
            "Extracting  static/assets/fonts/Flaticon.woff                            \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/flexslider-icon.eot                      \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/flexslider-icon.svg                      \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/flexslider-icon.ttf                      \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/flexslider-icon.woff                     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/fontawesome-webfont.eot                  \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/fontawesome-webfont.svg                  \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/fontawesome-webfont.ttf                  \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/fontawesome-webfont.woff                 \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/fontawesome-webfont.woff2                \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/FontAwesome.otf                          \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/slick.eot                                \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/slick.svg                                \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/slick.ttf                                \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/fonts/slick.woff                               \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Creating    static/assets/images                                      OK\n",
            "Extracting  static/assets/images/1.jpg                                   \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/about-image.jpg                         \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/client-01.png                           \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/fun-facts-bg.jpg                        \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/more-info.jpg                           \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/page-heading-bg.jpg                     \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/service_01.jpg                          \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/service_02.jpg                          \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/service_03.jpg                          \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/single_service_01.jpg                   \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/single_service_02.jpg                   \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/single_service_03.jpg                   \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/slide_01.jpg                            \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/slide_02.jpg                            \b\b\b\b 51%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/slide_03.jpg                            \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/slide_04.jpg                            \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/team_01.jpg                             \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/team_02.jpg                             \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/images/team_03.jpg                             \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Creating    static/assets/js                                          OK\n",
            "Extracting  static/assets/js/accordions.js                               \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/js/custom.js                                   \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/js/jquery.singlePageNav.min.js                 \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/js/owl.js                                      \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  static/assets/js/slick.js                                    \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Creating    static/vendor                                             OK\n",
            "Creating    static/vendor/bootstrap                                   OK\n",
            "Creating    static/vendor/bootstrap/css                               OK\n",
            "Extracting  static/vendor/bootstrap/css/bootstrap.css                    \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/css/bootstrap.css.map                \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/css/bootstrap.min.css                \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/css/bootstrap.min.css.map            \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Creating    static/vendor/bootstrap/js                                OK\n",
            "Extracting  static/vendor/bootstrap/js/bootstrap.bundle.js               \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/js/bootstrap.bundle.js.map           \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/js/bootstrap.bundle.min.js           \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/js/bootstrap.bundle.min.js.map       \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/js/bootstrap.js                      \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/js/bootstrap.js.map                  \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/js/bootstrap.min.js                  \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/bootstrap/js/bootstrap.min.js.map              \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Creating    static/vendor/jquery                                      OK\n",
            "Extracting  static/vendor/jquery/jquery.js                               \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/jquery/jquery.min.js                           \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/jquery/jquery.min.map                          \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/jquery/jquery.slim.js                          \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/jquery/jquery.slim.min.js                      \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  static/vendor/jquery/jquery.slim.min.map                     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  static/w3.css                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Creating    templates                                                 OK\n",
            "Extracting  templates/index.html                                         \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  templates/test.html                                          \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  4.0                                                          \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  nlp.py                                                       \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  Nouveau document texte.txt                                   \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAHWjADiLhGA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnAsAu2spA1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f9fe2c-84bf-491d-9f5c-d99913935623"
      },
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\")\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"tblard/tf-allocine\")\n",
        "\n",
        "nlp = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
            "\n",
            "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQCInYgVGg0X"
      },
      "source": [
        "Pour web application et pour aller vite, Flask est un framework de développement web en Python. Il en existe d’autres, le plus connu d’entre eux est Django mais avec Flask, on peut déjà rapidement obtenir des résultats, sans trop se perdre en Ce code commence par importer le module Flask "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSjQJg1sGhzA"
      },
      "source": [
        "from flask import Flask, request, render_template\n",
        "from flask_ngrok import run_with_ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXkoR4uFGnKx"
      },
      "source": [
        "On donne ensuite un nom à l’application ici ce sera app "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkE2Ou55Gpl3"
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when app is run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9tOmML5FgjA"
      },
      "source": [
        "Ensuite vient la partie cruciale : définir une page (ou route) avec flask @app.route permet de préciser à quelle adresse ce qui suit va s’appliquer.\n",
        "Ici comme on est sur la page d’accueil, on met juste (“/”)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gha-PzOrGwnA"
      },
      "source": [
        "Ensuite vient la page index.html qui va s’éxécuter sur la page “/”. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H39hVXhiPtBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c31766-2484-4367-cf6a-c43758d6607b"
      },
      "source": [
        "@app.route('/')\n",
        "\n",
        "def my_form():\n",
        "    return render_template('index.html')\n",
        "\n",
        "    \n",
        "@app.route('/', methods=['POST'])\n",
        "def my_form_post():\n",
        "    text1 = request.form['message'].lower()\n",
        "\n",
        "    a = nlp(text1)\n",
        "    text = a[0]['label']\n",
        "    score = a[0]['score']\n",
        "    score = round(score,6)\n",
        "    if text =='NEGATIVE' :\n",
        "      coleur = 'red'\n",
        "    else :\n",
        "      coleur = 'green'\n",
        "        \n",
        "    return render_template('test.html',scor=score,final=text,coleur=coleur) \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://72f8-104-199-74-189.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [01/Sep/2021 12:00:27] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:28] \"\u001b[37mGET /static/vendor/bootstrap/css/bootstrap.min.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:28] \"\u001b[37mGET /static/assets/css/fontawesome.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:28] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:28] \"\u001b[37mGET /static/assets/css/templatemo-finance-business.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:28] \"\u001b[37mGET /static/assets/css/owl.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/fonts/fontawesome-webfont.woff2?v=4.3.0 HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/vendor/jquery/jquery.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/vendor/bootstrap/js/bootstrap.bundle.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/css/owl.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/vendor/jquery/jquery.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/js/custom.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/css/templatemo-finance-business.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/css/fontawesome.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/vendor/bootstrap/css/bootstrap.min.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/vendor/bootstrap/js/bootstrap.bundle.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/js/owl.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/js/slick.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/js/accordions.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:29] \"\u001b[37mGET /static/assets/images/slide_01.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:30] \"\u001b[37mGET /static/assets/js/custom.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:30] \"\u001b[37mGET /static/assets/js/slick.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:30] \"\u001b[37mGET /static/assets/images/slide_02.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:30] \"\u001b[37mGET /static/assets/images/slide_03.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:30] \"\u001b[37mGET /static/assets/js/owl.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:30] \"\u001b[37mGET /static/assets/js/accordions.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:30] \"\u001b[37mGET /static/assets/images/slide_04.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:32] \"\u001b[37mGET /static/assets/images/slide_02.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:32] \"\u001b[37mGET /static/assets/images/slide_04.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:32] \"\u001b[37mGET /static/assets/images/slide_03.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:32] \"\u001b[37mGET /static/assets/fonts/fontawesome-webfont.woff2?v=4.3.0 HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:32] \"\u001b[37mGET /static/assets/images/slide_01.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:33] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:00:38] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:01:18] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 12:03:04] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}